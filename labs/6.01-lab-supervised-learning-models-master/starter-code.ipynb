{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.01 - Supervised Learning Model Comparison\n",
    "\n",
    "Recall the \"data science process.\"\n",
    "\n",
    "1. Define the problem.\n",
    "2. Gather the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Dictionary\n",
    "'''\n",
    "http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES\n",
    "Contains data from 401ksubs.dta\n",
    "  obs:         9,275                          \n",
    " vars:            11                          4 Sep 2001 13:50\n",
    " size:       231,875 (77.2% of memory free)\n",
    "-------------------------------------------------------------------------------\n",
    "              storage  display     value\n",
    "variable name   type   format      label      variable label\n",
    "-------------------------------------------------------------------------------\n",
    "e401k           byte   %9.0g                  =1 if eligble for 401(k)\n",
    "inc             float  %9.0g                  inc^2\n",
    "marr            byte   %9.0g                  =1 if married\n",
    "male            byte   %9.0g                  =1 if male respondent\n",
    "age             byte   %9.0g                  age^2\n",
    "fsize           byte   %9.0g                  family size\n",
    "nettfa          float  %9.0g                  net total fin. assets, $1000\n",
    "p401k           byte   %9.0g                  =1 if participate in 401(k)\n",
    "pira            byte   %9.0g                  =1 if have IRA\n",
    "incsq           float  %9.0g                  inc^2\n",
    "agesq           int    %9.0g                  age^2\n",
    "-------------------------------------------------------------------------------\n",
    "Sorted by:  \n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the datasets described in 'NOTE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_inc = df.drop(['e401k', 'p401k', 'pira', 'inc'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_inc = df['inc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_401k = df.drop('e401k', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_401k = df['e401k']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this as a source\n",
    "# https://www.irs.gov/retirement-plans/plan-sponsor/401k-plan-qualification-requirements\n",
    "# I am assuming the model is going to be used in the North American market\n",
    "\n",
    "# the IRS website is so dense, I don't even know what they are saying here! I'm an Engineer~ heck\n",
    "\n",
    "# Using another source:\n",
    "# https://www.forusall.com/401k-blog/401k-eligibility/\n",
    "# This one does a good job in explaining the jist but then offering their own service\n",
    "\n",
    "# another: \n",
    "# https://www.employeefiduciary.com/blog/401k-eligibility-when-to-let-employees-join-your-401k-plan\n",
    "\n",
    "# and another\n",
    "# https://www.investopedia.com/articles/retirement/08/401k-info.asp\n",
    "\n",
    "# Below, all of the information is compiled neatly into a few paragraphs and some reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would think another attribute that is important for considering if someone is eligable for a 401k would be:\n",
    "\n",
    "# Is the respondant at least X years old? (18, 19, 20, or 21) \n",
    "# Type: Bool\n",
    "# Minimium Age Requirement\n",
    "# Caveat, X cannot be higher than 21\n",
    "\n",
    "# Has the respondant serviced X hours to the employer? (Minimium hours worked to be considered eligable) \n",
    "# Type: Bool\n",
    "# Caveat: legally cannot be greater than 1 year for Safe Harbor\n",
    "# Caveat: legally cannot be greater than 2 years for discretionary employer contributiuons\n",
    "\n",
    "# Date that the respondant applied\n",
    "# Type: Datetime Object\n",
    "# Can be important if the employer has quarterly, semi annual, \n",
    "# annual enrollment dates for 401k for an automation system to report 401k application status\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very racist and gives data for discrimination and goes against the Civil Rights Act (1964)\n",
    "\n",
    "# <u> **IT IS IS VERY ILLEGAL**</u>\n",
    "\n",
    "## Civil Rights Act (1964), SEC. 2000e-2. [Section 703(h)]\n",
    "\n",
    ">(h) Seniority or merit system; quantity or quality of production; \n",
    ">ability tests; compensation based on sex and authorized by minimum wage provisions\n",
    "\n",
    ">Notwithstanding any other provision of this subchapter, it shall not be an\n",
    "unlawful employment practice for an employer to apply different standards of compensation, or different terms, conditions, or privileges of employment pursuant to a bona fide seniority or merit system, or a system which measures earnings by quantity or quality of production or to employees who work in different locations, provided that such <u>**differences are not the result of an intention to discriminate because of race, color,**</u> religion, sex, or national origin, <u>**nor shall it be an unlawful employment practice for an employer to give and to act upon the results of any professionally developed ability test provided that such test, its administration or action upon the results is not designed, intended or used to discriminate because of race, color,**</u> religion, sex or national origin. It shall not be an unlawful employment practice under this subchapter for any employer to differentiate upon the basis of sex in determining the amount of the wages or compensation paid or to be paid to employees of such employer if such differentiation is authorized by the provisions of section 206(d) of Title 29 [section 6(d) of the Labor Standards Act of 1938, as amended].\n",
    "\n",
    "## Civil Rights Act (1964) SEC. 2000e. [Section 701(k)]\n",
    "\n",
    ">(k) The terms \"because of sex\" or \"on the basis of sex\" include, \n",
    "but are not limited to, because of or on the basis of pregnancy, childbirth, \n",
    "or related medical conditions; and women affected by pregnancy, \n",
    "childbirth, or related medical conditions <u>**shall be treated the same \n",
    "for all employment-­related purposes, including receipt of benefits under \n",
    "fringe benefit programs, as other persons not so affected but similar in their \n",
    "ability or inability to work, and nothing in section 2000e-2(h) of this title \n",
    "[section 703(h)]**</u> shall be interpreted to permit otherwise. \n",
    "This subsection shall not require an employer to pay for health insurance \n",
    "benefits for abortion, except where the life of the mother would be endangered \n",
    "if the fetus were carried to term, or except where medical complications have arisen \n",
    "from an abortion: Provided, That nothing herein shall preclude an employer from providing \n",
    "abortion benefits or otherwise affect bargaining agreements in regard to abortion.\n",
    "\n",
    "## IRC 26 USC § 132(m)(1). Certain Fringe Benefits\n",
    "\n",
    "* (1) In general\n",
    "    * <u>**For purposes of this section, the term “qualified retirement planning services” means any retirement planning advice or information provided to an employee and his spouse by an employer maintaining a qualified employer plan.**</u>\n",
    "* (2) Nondiscrimination rule\n",
    "    * Subsection (a)(7) shall apply in the case of highly compensated employees only if such services are available on substantially the same terms to each member of the group of employees normally provided education and information regarding the employer’s qualified employer plan.\n",
    "* (3) Qualified employer plan\n",
    "    * <u>**For purposes of this subsection, the term “qualified employer plan” means a plan, contract, pension, or account described in section 219(g)(5).**</u>\n",
    "\n",
    "\n",
    "## IRC 26 U.S. Code § 219(g)(5). Retirement Savings\n",
    "\n",
    "* (5) Active participantFor purposes of this subsection, the term “active participant” means, with respect to any plan year, an individual—\n",
    "    * (A) who is an active participant in—\n",
    "        * (i) a plan described in section 401(a) which includes a trust exempt from tax under section 501(a),\n",
    "        * (ii) an annuity plan described in section 403(a),\n",
    "        * (iii) a plan established for its employees by the United States, by a State or political subdivision thereof, or by an agency or instrumentality of any of the foregoing,\n",
    "        * (iv) an annuity contract described in section 403(b),\n",
    "        * <u>**(v) a simplified employee pension (within the meaning of section 408(k)), or**</u>\n",
    "        * (vi) any simple retirement account (within the meaning of section 408(p)), or\n",
    "        \n",
    "## IRC 26 U.S. Code § 408(k)(1). Individual retirement accounts\n",
    "* (k) Simplified employee pension defined\n",
    "    * (1) In general, For purposes of this title, <u>**the term “simplified employee pension” means an individual retirement account or individual retirement annuity—**</u>\n",
    "\n",
    "## IRC 26 U.S. Code § 401(k). Cash or Deferred Payments\n",
    "* (2) Qualified cash or deferred arrangement: A qualified cash or deferred arrangement is any arrangement which is part of a profit-sharing or stock bonus plan, a pre-ERISA money purchase plan, or a rural cooperative plan which meets the requirements of subsection (a)—\n",
    "* (A) <u>**under which a covered employee may elect to have the employer make payments as contributions to a trust under the plan on behalf of the employee**</u>, or to the employee directly in cash;\n",
    "* (B) **under which amounts held by the trust which are attributable to employer contributions made pursuant to the employee’s election—**\n",
    "    * (i) may not be distributable to participants or other beneficiaries earlier than—\n",
    "        * (I) severance from employment, death, or disability,\n",
    "        * (II) an event described in paragraph (10),\n",
    "        * (III) in the case of a profit-sharing or stock bonus plan, the attainment of age 59½,\n",
    "        * (IV) subject to the provisions of paragraph (14), upon hardship of the employee,\n",
    "        * (V) in the case of a qualified reservist distribution (as defined in section 72(t)(2)(G)(iii)), the date on which a period referred to in subclause (III) of such section begins, or\n",
    "        * (VI) except as may be otherwise provided by regulations, with respect to amounts invested in a lifetime income investment (as defined in subsection (a)(38)(B)(ii)), the date that is 90 days prior to the date that such lifetime income investment may no longer be held as an investment option under the arrangement,\n",
    "    * (ii) will not be distributable merely by reason of the completion of a stated period of participation or the lapse of a fixed number of years, and\n",
    "    * (iii) except as may be otherwise provided by regulations, in the case of amounts described in clause (i)(VI), will be <u>**distributed only in the form of a qualified distribution (as defined in subsection (a)(38)(B)(i)) or a qualified plan distribution annuity contract (as defined in subsection (a)(38)(B)(iv)),**</u>\n",
    "* (C) which provides that an employee’s right to his accrued benefit derived from employer contributions made to the trust pursuant to his election is nonforfeitable, and\n",
    "* (D) which does not require, as a condition of participation in the arrangement, that an employee complete a period of service with the employer (or employers) maintaining the plan extending beyond the period permitted under section 410(a)(1) (determined without regard to subparagraph (B)(i) thereof).\n",
    "\n",
    "A 401(k) can be defined as an *Employee-Sponsored Defined-Contribution Pension Account*\n",
    "### References\n",
    "Source 1: Civil Rights Act (1964)\n",
    "https://www.eeoc.gov/statutes/title-vii-civil-rights-act-1964\n",
    "\n",
    "Source 2: Fringe Benefit\n",
    "https://www.irs.gov/pub/irs-tege/fringe_benefit_fslg.pdf\n",
    "\n",
    "Source 3: 26 U.S. Code § 132(m)(1)\n",
    "https://www.law.cornell.edu/uscode/text/26/132#m\n",
    "\n",
    "Source 4: 26 U.S. Code § 401(k)\n",
    "https://www.law.cornell.edu/uscode/text/26/401#k\n",
    "\n",
    "Source 5: IRC 26 U.S. Code § 219(g)(5)\n",
    "https://www.law.cornell.edu/uscode/text/26/219#g\n",
    "\n",
    "Source 6: IRC 26 U.S. Code § 408(k)(1)\n",
    "https://www.law.cornell.edu/uscode/text/26/408#k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal note\n",
    "# LAW is dense to understand, ugh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would stay from Family size, because the size of one's family does not dictate the amount of income. However, a larger family CAN encourage\n",
    "# one to pursue a better income, but does not necessarly imply a relationship between family and income\n",
    "\n",
    "# I can explore this later with a two tailed hypothesis test between family size and income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs might have done this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income Squared, Age Squared\n",
    "# The SME may consider that income and age are the strongest indicators for 401(k) elibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for 'inc' Data Dictionary labels it as 'inc^2'\n",
    "# This is the square root of 'inc^2', and can be understood as the income of a respondant in units of $1000\n",
    "# Justification:\n",
    "# We can relate this column to the 'nettfa' column, which described the net total financial assets of a respondant in units of $1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this as a neat graphic:\n",
    "# https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "## Nice and simple, we know this. Consider the independent variables of X and fit to Y.\n",
    "## Always a good place to start\n",
    "\n",
    "# Lasso\n",
    "# Least Absolute Shrinkage and selector operator\n",
    "# Differing from LR, alters the modeling process to select a subset of the provided independent numerical features for use in the final model,\n",
    "# instead of all of them. Forces the sum of the absolute value of the regression coefficents to be less than a fixed value, where some \n",
    "# coefficents of independent numerical features are forced to zero\n",
    "# This chooses a simpler model which does not include these coefficents.\n",
    "# This process automatically removes outlier datapoints in the independent numerical features\n",
    "# Good to compare against\n",
    "\n",
    "# Ridge\n",
    "# Like Lasso, but coefficents of numerical features are reduced to reduce their effect on predicting the dependent numerical feature,\n",
    "# so the result is a model which considers all the independent numerical features - but not as complex as a linear regression and \n",
    "# weighs some coefficents more heavily\n",
    "# Good to compare against, would be interesting to see vs Lasso and see a simple model vs a weighted model\n",
    "\n",
    "# ElasticNet\n",
    "# Both Lasso and Ridge\n",
    "# One or the other, let's try both!\n",
    "\n",
    "# Support Vector Regression (SVR)\n",
    "# Depends on a subset of the data, ignores data points that are beyond the margin (another outlier remover),\n",
    "# fits a linear equation that deviates no more than the median, while trying to be as flat as possible\n",
    "# In my experience, I have not found these successful for regression however I did not tune the hyperparameters\n",
    "\n",
    "# Ensemble Regressor - Bagging\n",
    "# Fits a linear regression to multiple sets of data sampled from the training data with replacement through a process called bootstrapping\n",
    "# Averages out the collection of linear models into one which best represented the set\n",
    "# Good for working with limited data\n",
    "\n",
    "# Ensemble Regressor - Voting Regressor\n",
    "# Combines many weak linear models into one stronger model by giving each model a weight\n",
    "# can be good to experiment combining some of the earlier linear models like LR and Lasso into one regression workflow\n",
    "\n",
    "# K Nearest Regressors\n",
    "# Uses a classification technique for regression where interpolation is done on the nearest datapoints in the training set\n",
    "# Tends to overfit\n",
    "\n",
    "# Decison Tree Regressor\n",
    "# Tends to overfit\n",
    "# optimizes local criteria between optimal features and sorts training data into groups, tends to overfit\n",
    "\n",
    "# Random Forest Regressor\n",
    "# Like Extra Trees, but is an assortment of optimzied decision trees which optimize for local crtieria\n",
    "# Is then averaged out \n",
    "\n",
    "# Extra Tree Regressor\n",
    "# Makes a collection of decision tree regressors but each one is split at random instead of optimized local criteria - the collection of \n",
    "# trees are then averged out to control overfitting and bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector regressor\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linear estimators\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# import structure and preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datascience.stackexchange.com/questions/45900/when-to-use-standard-scaler-and-when-normalizer\n",
    "# This recommends to normalize data for linear regression\n",
    "estimator_dict = {'lr': LinearRegression(normalize=True),\n",
    "                  'knn': KNeighborsRegressor(), # Standardize, because KNN uses a classification approach\n",
    "                 'dtr': DecisionTreeRegressor(), # Don't Standardize, Don't normalize\n",
    "                 'br': BaggingRegressor(), # Normalize\n",
    "                 'rfr': RandomForestRegressor(), # Don't Standardize, Don't normalize\n",
    "                 'abr': AdaBoostRegressor(), # normalize\n",
    "                 'svr': SVR()} # Standardize, SVR uses a classification approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipes(estimator_list):\n",
    "    pipe_list = []\n",
    "    for estimator in estimator_list.keys():\n",
    "        if estimator in ['lr', 'svr']:\n",
    "            #standardize\n",
    "            pipe_list.append(make_pipeline(StandardScaler(), estimator_list.get(estimator)))\n",
    "        if estimator in ['br', 'abr']:\n",
    "             # normalize\n",
    "            pipe_list.append(make_pipeline(Normalizer(), estimator_list.get(estimator)))\n",
    "        else:\n",
    "            pipe_list.append(estimator_list.get(estimator))\n",
    "    return dict(zip(estimator_list.keys(),pipe_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict = make_pipes(estimator_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('linearregression', LinearRegression(normalize=True))]),\n",
       " 'knn': LinearRegression(normalize=True),\n",
       " 'dtr': KNeighborsRegressor(),\n",
       " 'br': DecisionTreeRegressor(),\n",
       " 'rfr': Pipeline(steps=[('normalizer', Normalizer()),\n",
       "                 ('baggingregressor', BaggingRegressor())]),\n",
       " 'abr': RandomForestRegressor(),\n",
       " 'svr': Pipeline(steps=[('normalizer', Normalizer()),\n",
       "                 ('adaboostregressor', AdaBoostRegressor())])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lr',\n",
       "  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                  ('linearregression', LinearRegression(normalize=True))])),\n",
       " ('knn', LinearRegression(normalize=True)),\n",
       " ('dtr', KNeighborsRegressor()),\n",
       " ('br', DecisionTreeRegressor()),\n",
       " ('rfr',\n",
       "  Pipeline(steps=[('normalizer', Normalizer()),\n",
       "                  ('baggingregressor', BaggingRegressor())])),\n",
       " ('abr', RandomForestRegressor()),\n",
       " ('svr',\n",
       "  Pipeline(steps=[('normalizer', Normalizer()),\n",
       "                  ('adaboostregressor', AdaBoostRegressor())]))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,j) for i,j in pipe_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring back the dataframes we set up0 for this regression problem to predict inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   marr  male  age  fsize   nettfa      incsq  agesq\n",
       "0     0     0   40      1    4.575   173.4489   1600\n",
       "1     0     1   35      1  154.000  3749.1130   1225\n",
       "2     1     0   44      2    0.000   165.3282   1936\n",
       "3     1     1   44      2   21.800  9777.2540   1936\n",
       "4     0     0   53      1   18.450   511.3930   2809"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_inc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13.170\n",
       "1    61.230\n",
       "2    12.858\n",
       "3    98.880\n",
       "4    22.614\n",
       "Name: inc, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_inc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_x_inc, df_y_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipes(pipe_dict, X, y):\n",
    "    import datetime as dt\n",
    "    fitted_object = []\n",
    "    for (name, pipe) in pipe_dict.items():\n",
    "        # time\n",
    "        time_start = dt.datetime.now()\n",
    "        # Fit\n",
    "        pipe.fit(X_train, y_train)\n",
    "        fitted_object.append(pipe)\n",
    "        # Score\n",
    "        train_score = pipe.score(X_train, y_train)\n",
    "        test_score = pipe.score(X_test, y_test)\n",
    "        time_done = dt.datetime.now()\n",
    "        print(f'  Estimator: {name}\\nTrain Score: {train_score}, \\n Test Score: {test_score} \\n Time Taken: {time_done-time_start}')\n",
    "    return dict(zip(pipe_dict.keys(),fitted_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estimator: lr\n",
      "Train Score: 0.896920916713926, \n",
      " Test Score: 0.8987138066168298 \n",
      " Time Taken: 0:00:00.034830\n",
      "  Estimator: knn\n",
      "Train Score: 0.896920916713926, \n",
      " Test Score: 0.8987138066168296 \n",
      " Time Taken: 0:00:00.023233\n",
      "  Estimator: dtr\n",
      "Train Score: 0.9998597874294675, \n",
      " Test Score: 0.9998088730728123 \n",
      " Time Taken: 0:00:00.128774\n",
      "  Estimator: br\n",
      "Train Score: 1.0, \n",
      " Test Score: 0.9999776716691973 \n",
      " Time Taken: 0:00:00.052865\n",
      "  Estimator: rfr\n",
      "Train Score: 0.9996029036372284, \n",
      " Test Score: 0.9985471231878682 \n",
      " Time Taken: 0:00:00.450361\n",
      "  Estimator: abr\n",
      "Train Score: 0.9999955560599776, \n",
      " Test Score: 0.9999850667234504 \n",
      " Time Taken: 0:00:02.969707\n",
      "  Estimator: svr\n",
      "Train Score: 0.9478263802749243, \n",
      " Test Score: 0.9407818027370883 \n",
      " Time Taken: 0:00:00.721584\n"
     ]
    }
   ],
   "source": [
    "fitted_objects = evaluate_pipes(pipe_dict, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# They all did very well. I don't know how to feel, but I do feel confident in the standardization/normalization approach i took"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat a training dataset as a population\n",
    "# Create a set of sampled data from the population with replacement\n",
    "# Eg: Training Dataset: [1, 2, 3, 4, 5]\n",
    "# One Bagged Sample: [ 1, 2, 2, 4, 5]\n",
    "# Bootstrapping, doing this process many times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A decision tree fits the data into groups, optimizing at each node\n",
    "\n",
    "# a set of bagged decision trees creates a set of bagged samples (bootstrapping), fits each bagged sample to a decision tree\n",
    "# returns the average of all the decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bagged decision tree optimzes at each node\n",
    "# returns the average of all the decision trees that have optimized nodes\n",
    "\n",
    "# A random forest chooses the split at each node randomly for each bagged sample\n",
    "# returns the average of all the decision trees with nodes that are randomly split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding randomization to decision tree nodes fights the inherent bias in locally fitting nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rsme(fitted_dist, x_train, x_test, y_train, y_test):\n",
    "    train_preds = []\n",
    "    test_preds = []\n",
    "    train_rsme = []\n",
    "    test_rsme = []\n",
    "    for (name, fitted) in fitted_dist.items():\n",
    "        train_pred = fitted.predict(x_train)\n",
    "        train_preds.append(train_pred)\n",
    "        \n",
    "        test_pred = fitted.predict(x_test)\n",
    "        test_preds.append(test_pred)\n",
    "        \n",
    "        train_error = mean_squared_error(y_train, train_pred, squared=False)\n",
    "        test_error = mean_squared_error(y_test, test_pred, squared=False)\n",
    "        train_rsme.append(train_error)\n",
    "        test_rsme.append(test_error)\n",
    "        print(f'Object: {name}\\nTrain RSME: {train_error}\\nTest RSME: {test_error}')\n",
    "    return [fitted_dist.keys(), train_rsme, test_rsme], (train_preds, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: lr\n",
      "Train RSME: 44.81837090851578\n",
      "Test RSME: 43.266666632373436\n",
      "Object: knn\n",
      "Train RSME: 7.810476214323787\n",
      "Test RSME: 7.426431959880675\n",
      "Object: dtr\n",
      "Train RSME: 0.28806183045591527\n",
      "Test RSME: 0.32260123118121836\n",
      "Object: br\n",
      "Train RSME: 5.455095342872254e-16\n",
      "Test RSME: 0.11026386479376801\n",
      "Object: rfr\n",
      "Train RSME: 0.48477497756031385\n",
      "Test RSME: 0.8894457780308594\n",
      "Object: abr\n",
      "Train RSME: 0.05128334383433123\n",
      "Test RSME: 0.09017427009634375\n",
      "Object: svr\n",
      "Train RSME: 5.556709906218215\n",
      "Test RSME: 5.678487484086371\n"
     ]
    }
   ],
   "source": [
    "rsme, preds = evaluate_rsme(fitted_objects, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lr', 'knn', 'dtr', 'br', 'rfr', 'abr', 'svr'])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsme[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rsme = pd.DataFrame([rsme[1], rsme[2]] , index=['RSME Train', 'RSME Test'], columns=list(rsme[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rsme = df_rsme.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rsme = df_rsme.sort_values(by='RSME Test', ascending=True).round(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rsme['RSME Train - Test'] = df_rsme['RSME Train'] - df_rsme['RSME Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSME Train</th>\n",
       "      <th>RSME Test</th>\n",
       "      <th>RSME Train - Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abr</th>\n",
       "      <td>0.051283</td>\n",
       "      <td>0.090174</td>\n",
       "      <td>-0.038891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110264</td>\n",
       "      <td>-0.110264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtr</th>\n",
       "      <td>0.288062</td>\n",
       "      <td>0.322601</td>\n",
       "      <td>-0.034539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfr</th>\n",
       "      <td>0.484775</td>\n",
       "      <td>0.889446</td>\n",
       "      <td>-0.404671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svr</th>\n",
       "      <td>5.556710</td>\n",
       "      <td>5.678487</td>\n",
       "      <td>-0.121778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>7.810476</td>\n",
       "      <td>7.426432</td>\n",
       "      <td>0.384044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>44.818371</td>\n",
       "      <td>43.266667</td>\n",
       "      <td>1.551704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RSME Train  RSME Test  RSME Train - Test\n",
       "abr    0.051283   0.090174          -0.038891\n",
       "br     0.000000   0.110264          -0.110264\n",
       "dtr    0.288062   0.322601          -0.034539\n",
       "rfr    0.484775   0.889446          -0.404671\n",
       "svr    5.556710   5.678487          -0.121778\n",
       "knn    7.810476   7.426432           0.384044\n",
       "lr    44.818371  43.266667           1.551704"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rsme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineered Column can quickly give us information\n",
    "# Anything with a negative value, the model overfitted, the larger the negative differnce the larger the overfit\n",
    "\n",
    "# Anything with a positive value the model was able to generalize, the larger the positive differende the higher the learned relationships\n",
    "\n",
    "# However, this is in relation to each model when comparing overfitting. Refer to the Test RSME score for how the model learned the \n",
    "# relationships of the independent features to the predictor features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would Choose the AdaBoostedRegressor Model for the regression problem\n",
    "# There is slight overfitting with the training data but out of all the evaluated models\n",
    "# It has the lowest test RSME and may have best learned the relationships between the independent numerical features and the predictor\n",
    "\n",
    "# To improve on this, I would most likely include abr into a ensemble voter and include another estimator such as knn to combat the overfitting\n",
    "# with more variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would preform a quick gridcv search over 3 kinds of values:\n",
    "# much smaller than default, default, much larger than default\n",
    "\n",
    "# Then I would evaluate RSME for all possible estmators and visually identify a trend for where RSME is lowest\n",
    "# Then gridsearch CV over the identified range where RSME was calculated lowest\n",
    "\n",
    "# There is most likely a way to optimize this process, like stochastic gradient descent? I don't know yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p401k is a variable which states if a customer already has a 401k, possibly with a previous employer\n",
    "# This won't mean much for our eligibility terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# K Nearest Neighbors Classification\n",
    "# Decision Tree Classifier\n",
    "# Bagged Classifier\n",
    "# Random Forest Classifier\n",
    "# Adaboost classifier\n",
    "# Support Vector Classification\n",
    "\n",
    "# Multinominal Naive Bayes\n",
    "# Ensemble Classifiers - Bagging\n",
    "# Ensemble Classifier - Voting Classifier\n",
    "# Extra trees classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    - a support vector classifier\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
